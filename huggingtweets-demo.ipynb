{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingTweets - Tweet Generation with Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: this demo is not to be used to publish any false generated information but to perform research on Natural Language Generation (NLG).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface scripts for fine-tuning models and language generation\n",
    "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py -q\n",
    "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "import urllib3\n",
    "import random\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Download tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a Twitter user and download his tweets.\n",
    "\n",
    "*Note*: Huggingtweets works only if the user has a lot of tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_text(text):\n",
    "    text = text.replace('&amp;', '&')\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_tweet(tweet):\n",
    "    \"Clean tweet text\"\n",
    "    text = ' '.join(t for t in tweet.split() if 'http' not in t)\n",
    "    if text.split() and text.split()[0] == '.':\n",
    "         text = ' '.join(text.split()[1:])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boring_tweet(tweet):\n",
    "    \"Check if this is a boring tweet\"\n",
    "    boring_stuff = ['http', '@', '#', 'thank', 'thanks', 'I', 'you']\n",
    "    if len(tweet.split()) < 3:\n",
    "        return True\n",
    "    if all(any(bs in t.lower() for bs in boring_stuff) for t in tweet):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_tweets(handle_value):\n",
    "    handle = handle_value[1:] if handle_value[0] == '@' else handle_value\n",
    "    run_dl_tweets.button_style = 'primary'\n",
    "    log_dl_tweets.clear_output()\n",
    "    with log_dl_tweets:\n",
    "        try:\n",
    "            print(f'\\nDownloading {handle_value} tweets… This should take no more than a minute!')\n",
    "            http = urllib3.PoolManager(retries=urllib3.Retry(3))\n",
    "            res = http.request(\"GET\", f\"https://us-central1-playground-111.cloudfunctions.net/tweets_http?handle={handle}\")\n",
    "            curated_tweets = json.loads(res.data.decode('utf-8'))\n",
    "            curated_tweets = [fix_text(tweet) for tweet in curated_tweets]\n",
    "            log_dl_tweets.clear_output()\n",
    "            print(f'\\n{len(curated_tweets)} tweets from {handle_value} downloaded!')\n",
    "            random.shuffle(curated_tweets)\n",
    "            for i,t in enumerate(curated_tweets[:5]):\n",
    "                print(f'\\nExample #{i+1}\\n{t}')\n",
    "                \n",
    "            # create dataset\n",
    "            clean_tweets = [cleanup_tweet(t) for t in curated_tweets]\n",
    "            cool_tweets = [tweet for tweet in clean_tweets if not boring_tweet(tweet)]\n",
    "            with open('{}_train.txt'.format(handle), 'w') as f:\n",
    "                f.write('\\n'.join(cool_tweets))\n",
    "            \n",
    "            run_dl_tweets.button_style = 'success'\n",
    "        except:\n",
    "            print('An error occured…')\n",
    "            run_dl_tweets.button_style = 'danger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_widget = widgets.Text(value='@karpathy',\n",
    "                             placeholder='Enter twitter handle',\n",
    "                             description='User:')\n",
    "\n",
    "run_dl_tweets = widgets.Button(\n",
    "    description='Download tweets',\n",
    "    button_style='primary')\n",
    "def on_run_dl_tweets_clicked(b):\n",
    "    dl_tweets(handle_widget.value)\n",
    "run_dl_tweets.on_click(on_run_dl_tweets_clicked)\n",
    "\n",
    "log_dl_tweets = widgets.Output()\n",
    "with log_dl_tweets:\n",
    "    print('\\nEnter a Twitter handle and click \"Download tweets\"')\n",
    "\n",
    "widgets.VBox([widgets.HBox([handle_widget, run_dl_tweets]), log_dl_tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train your Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), a neural network which was trained to predict next words by reading large quantity of Internet text.\n",
    "\n",
    "We fine-tune the model on our tweets using [Huggingface](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate run to a project\n",
    "%env WANDB_PROJECT=huggingtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune():\n",
    "    handle = handle_widget.value[1:] if handle_widget.value[0] == '@' else handle_widget.value\n",
    "    run_finetune.button_style = 'primary'\n",
    "    log_finetune.clear_output()\n",
    "    with log_finetune:\n",
    "        try:\n",
    "            print(f'\\nTraining Neural Network on {handle_widget.value} tweets… This could take up to 10 minutes!')\n",
    "            !python run_language_modeling.py \\\n",
    "                --output_dir=output/$handle \\\n",
    "                --overwrite_output_dir \\\n",
    "                --model_type=gpt2 \\\n",
    "                --model_name_or_path=gpt2 \\\n",
    "                --do_train --train_data_file=$handle\\_train.txt \\\n",
    "                --logging_steps 0 \\\n",
    "                --per_gpu_train_batch_size 1 \\\n",
    "                --num_train_epochs 4\n",
    "            \n",
    "            print('\\n\\nTraining Complete and Successful!!!')\n",
    "            \n",
    "            run_finetune.button_style = 'success'\n",
    "        except:\n",
    "            print('An error occured…')\n",
    "            run_finetune.button_style = 'danger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_finetune = widgets.Button(\n",
    "    description='Train Neural Network',\n",
    "    button_style='primary')\n",
    "def on_run_finetune_clicked(b):\n",
    "    finetune()\n",
    "run_finetune.on_click(on_run_finetune_clicked)\n",
    "\n",
    "log_finetune = widgets.Output()\n",
    "with log_finetune:\n",
    "    print('\\nFine-tune your model by clicking on \"Train Neural Network\"')\n",
    "\n",
    "widgets.VBox([run_finetune, log_finetune])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Predictions and Have Fun!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model trained successfully, we can now visualize predictions!\n",
    "\n",
    "We just start a sentence and let the model finish it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    handle = handle_widget.value[1:] if handle_widget.value[0] == '@' else handle_widget.value\n",
    "    start = start_widget.value\n",
    "    run_predictions.button_style = 'primary'\n",
    "    log_predictions.clear_output()\n",
    "    with log_predictions:\n",
    "        try:\n",
    "            print(f'\\nPerforming predictions of {handle_widget.value} starting with \"{start}\"…\\nThis should take no more than a minute!')\n",
    "            seed = random.randint(0, 2**32-1)\n",
    "            val = !python run_generation.py \\\n",
    "                --model_type gpt2 \\\n",
    "                --model_name_or_path output/$handle \\\n",
    "                --length 150 \\\n",
    "                --stop_token \"{'\\n'}\" \\\n",
    "                --num_return_sequences 5 \\\n",
    "                --temperature 1 \\\n",
    "                --seed $seed \\\n",
    "                --prompt {'\"' + start + '\"'}\n",
    "            generated = [val[-1-2*k] for k in range(5)[::-1]]\n",
    "            log_predictions.clear_output()\n",
    "            print(f'\\nPredictions of {handle_widget.value} starting with \"{start}\" on #huggingtweet')\n",
    "            for i, g in enumerate(generated):\n",
    "                g = g.replace('<|endoftext|>', '')\n",
    "                print(f'\\nPrediction #{i+1}: {g}')\n",
    "            \n",
    "            run_predictions.button_style = 'success'\n",
    "        except:\n",
    "            print('An error occured…')\n",
    "            run_predictions.button_style = 'danger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_widget = widgets.Text(value='I want',\n",
    "                            placeholder='Enter twitter handle',\n",
    "                            description='Start:')\n",
    "\n",
    "run_predictions = widgets.Button(\n",
    "    description='Run predictions',\n",
    "    button_style='primary')\n",
    "def on_run_predictions_clicked(b):\n",
    "    predict()\n",
    "run_predictions.on_click(on_run_predictions_clicked)\n",
    "\n",
    "log_predictions = widgets.Output()\n",
    "with log_predictions:\n",
    "    print('\\nEnter the start of a sentence and click \"Run predictions\"')\n",
    "\n",
    "widgets.VBox([widgets.HBox([start_widget, run_predictions]), log_predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
