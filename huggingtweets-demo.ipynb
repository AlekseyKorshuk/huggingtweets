{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingTweets - Tweet Generation with Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: this demo is not to be used to publish any false generated information but to perform research on Natural Language Generation (NLG).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Huggingface scripts for fine-tuning models and language generation\n",
    "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py -q\n",
    "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py -q\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import urllib3\n",
    "import random\n",
    "import wandb\n",
    "import click\n",
    "\n",
    "def fix_text(text):\n",
    "    text = text.replace('&amp;', '&')\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    return text\n",
    "\n",
    "def cleanup_tweet(tweet):\n",
    "    \"Clean tweet text\"\n",
    "    text = ' '.join(t for t in tweet.split() if 'http' not in t)\n",
    "    if text.split() and text.split()[0] == '.':\n",
    "         text = ' '.join(text.split()[1:])\n",
    "    return text\n",
    "\n",
    "def boring_tweet(tweet):\n",
    "    \"Check if this is a boring tweet\"\n",
    "    boring_stuff = ['http', '@', '#', 'thank', 'thanks', 'I', 'you']\n",
    "    if len(tweet.split()) < 3:\n",
    "        return True\n",
    "    if all(any(bs in t.lower() for bs in boring_stuff) for t in tweet):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def dl_tweets(handle_value):\n",
    "    handle = handle_value[1:] if handle_value[0] == '@' else handle_value\n",
    "    run_dl_tweets.button_style = 'primary'\n",
    "    log_dl_tweets.clear_output()\n",
    "    with log_dl_tweets:\n",
    "        try:\n",
    "            print(f'\\nDownloading {handle_value} tweets... This should take no more than a minute!')\n",
    "            http = urllib3.PoolManager(retries=urllib3.Retry(3))\n",
    "            res = http.request(\"GET\", f\"http://us-central1-playground-111.cloudfunctions.net/tweets_http?handle={handle}\")\n",
    "            curated_tweets = json.loads(res.data.decode('utf-8'))\n",
    "            curated_tweets = [fix_text(tweet) for tweet in curated_tweets]\n",
    "            log_dl_tweets.clear_output()\n",
    "            print(f'\\n{len(curated_tweets)} tweets from {handle_value} downloaded!')\n",
    "            random.shuffle(curated_tweets)\n",
    "            for i,t in enumerate(curated_tweets[:5]):\n",
    "                print(f'\\nExample #{i+1}\\n{t}')\n",
    "                \n",
    "            # create dataset\n",
    "            clean_tweets = [cleanup_tweet(t) for t in curated_tweets]\n",
    "            cool_tweets = [tweet for tweet in clean_tweets if not boring_tweet(tweet)]\n",
    "            with open('{}_train.txt'.format(handle), 'w') as f:\n",
    "                f.write('\\n'.join(cool_tweets))\n",
    "            \n",
    "            run_dl_tweets.button_style = 'success'\n",
    "        except Exception as e:\n",
    "            print('An error occured...\\n')\n",
    "            print(e)\n",
    "            run_dl_tweets.button_style = 'danger'\n",
    "            \n",
    "handle_widget = widgets.Text(value='@karpathy',\n",
    "                             placeholder='Enter twitter handle',\n",
    "                             description='User:')\n",
    "\n",
    "run_dl_tweets = widgets.Button(\n",
    "    description='Download tweets',\n",
    "    button_style='primary')\n",
    "def on_run_dl_tweets_clicked(b):\n",
    "    dl_tweets(handle_widget.value)\n",
    "run_dl_tweets.on_click(on_run_dl_tweets_clicked)\n",
    "\n",
    "log_dl_tweets = widgets.Output()\n",
    "with log_dl_tweets:\n",
    "    print('\\nEnter a Twitter handle and click \"Download tweets\"')\n",
    "    \n",
    "# Associate run to a project\n",
    "%env WANDB_PROJECT=huggingtweets\n",
    "%env WANDB_WATCH=false\n",
    "wandb.login(anonymous='allow')\n",
    "\n",
    "def finetune():\n",
    "    handle = handle_widget.value[1:] if handle_widget.value[0] == '@' else handle_widget.value\n",
    "    run_finetune.button_style = 'primary'\n",
    "    log_finetune.clear_output()\n",
    "    with log_finetune:\n",
    "        try:\n",
    "            print(f'\\nTraining Neural Network on {handle_widget.value} tweets... This could take up to 5-10 minutes!')\n",
    "            !python run_language_modeling.py \\\n",
    "                --output_dir=output/$handle \\\n",
    "                --overwrite_output_dir \\\n",
    "                --model_type=gpt2 \\\n",
    "                --model_name_or_path=gpt2 \\\n",
    "                --do_train --train_data_file=$handle\\_train.txt \\\n",
    "                --logging_steps 20 \\\n",
    "                --per_gpu_train_batch_size 1 \\\n",
    "                --num_train_epochs 4\n",
    "            \n",
    "            print('\\n\\nTraining Complete and Successful!!!')\n",
    "            \n",
    "            run_finetune.button_style = 'success'\n",
    "        except Exception as e:\n",
    "            print('An error occured...\\n')\n",
    "            print(e)\n",
    "            run_finetune.button_style = 'danger'\n",
    "\n",
    "run_finetune = widgets.Button(\n",
    "    description='Train Neural Network',\n",
    "    button_style='primary')\n",
    "def on_run_finetune_clicked(b):\n",
    "    finetune()\n",
    "run_finetune.on_click(on_run_finetune_clicked)\n",
    "\n",
    "log_finetune = widgets.Output()\n",
    "with log_finetune:\n",
    "    print('\\nFine-tune your model by clicking on \"Train Neural Network\"')\n",
    "    \n",
    "predictions = []\n",
    "tweet_share = None\n",
    "\n",
    "def predict():\n",
    "    handle = handle_widget.value[1:] if handle_widget.value[0] == '@' else handle_widget.value\n",
    "    start = start_widget.value\n",
    "    run_predictions.button_style = 'primary'\n",
    "    log_predictions.clear_output()\n",
    "    \n",
    "    prediction_success = False\n",
    "    with log_predictions:\n",
    "        try:\n",
    "            print(f'\\nPerforming predictions of {handle_widget.value} starting with \"{start}\"...\\nThis should take no more than 20 seconds!')\n",
    "            \n",
    "            # load previous run\n",
    "            project = %env WANDB_PROJECT\n",
    "            wandb_id = wandb.api.list_runs(project)[0]['name']\n",
    "            wandb.init(id=wandb_id, resume='must')\n",
    "            wandb_url = wandb.run.get_url()\n",
    "            \n",
    "            seed = random.randint(0, 2**32-1)\n",
    "            val = !python run_generation.py \\\n",
    "                --model_type gpt2 \\\n",
    "                --model_name_or_path output/$handle \\\n",
    "                --length 150 \\\n",
    "                --stop_token \"{'\\n'}\" \\\n",
    "                --num_return_sequences 5 \\\n",
    "                --temperature 1 \\\n",
    "                --seed $seed \\\n",
    "                --prompt {'\"' + start + '\"'}\n",
    "            generated = [val[-1-2*k] for k in range(5)[::-1]]\n",
    "            log_predictions.clear_output()\n",
    "            print(f'\\nPredictions of {handle_widget.value} starting with \"{start}\" on #huggingtweet')\n",
    "            for i, g in enumerate(generated):\n",
    "                g = g.replace('<|endoftext|>', '')\n",
    "                print(f'\\nPrediction #{i+1}: {g}')\n",
    "                predictions.append([start, g])\n",
    "            \n",
    "            # log predictions\n",
    "            wandb.log({'examples': wandb.Table(data=predictions, columns=['Input', 'Prediction'])})\n",
    "            \n",
    "            # Update display name\n",
    "            wandb.run.name = handle\n",
    "            wandb.run.save()\n",
    "            \n",
    "            # display wandb run\n",
    "            print(f'\\nðŸš€ View results under the \"Media\" panel at {click.style(wandb_url, underline=True, fg=\"blue\")}')            \n",
    "            \n",
    "            run_predictions.button_style = 'success'\n",
    "            prediction_success = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('An error occured...\\n')\n",
    "            print(e)\n",
    "            run_predictions.button_style = 'danger'\n",
    "            \n",
    "    log_tweet.clear_output()\n",
    "    if not prediction_success: return\n",
    "    with log_tweet:\n",
    "        try:\n",
    "            # update tweet group\n",
    "            max_char = 120\n",
    "            tweet_selection.options = [p[1][:max_char] if len(p[1])<max_char else p[1][:max_char]+'...' for p in predictions[-5:]]\n",
    "            tweet_selection.layout.visibility = 'visible'\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('An error occured...\\n')\n",
    "            print(e)\n",
    "            \n",
    "start_widget = widgets.Text(value='I want',\n",
    "                            placeholder='Enter twitter handle',\n",
    "                            description='Start:')\n",
    "\n",
    "run_predictions = widgets.Button(\n",
    "    description='Run predictions',\n",
    "    button_style='primary')\n",
    "def on_run_predictions_clicked(b):\n",
    "    predict()\n",
    "run_predictions.on_click(on_run_predictions_clicked)\n",
    "\n",
    "log_predictions = widgets.Output()\n",
    "with log_predictions:\n",
    "    print('\\nEnter the start of a sentence and click \"Run predictions\"')\n",
    "    \n",
    "tweet_selection = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Best tweet:',\n",
    "    disabled=False,\n",
    ")\n",
    "tweet_selection.layout.visibility = 'hidden'\n",
    "\n",
    "log_tweet = widgets.Output()\n",
    "\n",
    "def handle_tweet_change(change):\n",
    "    handle = handle_widget.value[1:] if handle_widget.value[0] == '@' else handle_widget.value\n",
    "    start = start_widget.value\n",
    "    wandb_url = wandb.run.get_url()\n",
    "    \n",
    "    log_tweet.clear_output()\n",
    "    with log_tweet:\n",
    "        try:\n",
    "            max_char = 130\n",
    "            tweet_selected = tweet_selection.value.replace('\"','&quot;')\n",
    "            tweet_html = '<a href=\"https://twitter.com/share?ref_src=twsrc%5Etfw\" class=\"twitter-share-button\" data-size=\"large\" '\\\n",
    "                     f'data-text=\"Love this fake tweet: @{handle} + &quot;'\\\n",
    "                     f'{start}&quot; = &quot;{tweet_selected}&quot;\" '\\\n",
    "                     f'data-url=\"{wandb_url}\" data-hashtags=\"huggingtweets\" data-related=\"borisdayma,weights_biases,huggingface\"'\\\n",
    "                     'data-show-count=\"false\">Tweet</a><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>'\n",
    "            display(HTML(tweet_html))\n",
    "        except Exception as e:\n",
    "            print('An error occured...\\n')\n",
    "            print(e)\n",
    "            \n",
    "tweet_selection.observe(handle_tweet_change, names='value')\n",
    "\n",
    "show_step_1 = widgets.VBox([widgets.HBox([handle_widget, run_dl_tweets]), log_dl_tweets])\n",
    "\n",
    "show_step_2 = widgets.VBox([run_finetune, log_finetune])\n",
    "\n",
    "show_step_3 = widgets.VBox([widgets.HBox([start_widget, run_predictions]), log_predictions])\n",
    "\n",
    "show_step_4 = widgets.VBox([tweet_selection, log_tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Download tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a Twitter user and download his tweets.\n",
    "\n",
    "*Note*: Huggingtweets works only if the user has a lot of tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9ab74fe8fd496f9ee77105356f3d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='@karpathy', description='User:', placeholder='Enter twitter handle')â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_step_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train your Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), a neural network which was trained to predict next words by reading large quantity of Internet text.\n",
    "\n",
    "We fine-tune the model on our tweets using [Huggingface](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7140f335868484c9a931099e8db7850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='primary', description='Train Neural Network', style=ButtonStyle()), Outputâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_step_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Predictions and Have Fun!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model trained successfully, we can now visualize predictions!\n",
    "\n",
    "We just start a sentence and let the model finish it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0863639de340dabec1abf30a395191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='I want', description='Start:', placeholder='Enter twitter handle'), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_step_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Share your favorite results with #huggingtweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would love to see your favorite predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3c2e009e1a44f99df787156db553d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Best tweet:', layout=Layout(visibility='hidden'), options=(), value=None)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_step_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the model works, visit the project repository.\n",
    "\n",
    "[![GitHub stars](https://img.shields.io/github/stars/borisdayma/huggingtweets?style=social)](https://github.com/borisdayma/huggingtweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
